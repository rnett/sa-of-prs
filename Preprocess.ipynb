{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List\n",
    "from langdetect import detect\n",
    "from tqdm import tqdm\n",
    "\n",
    "import data\n",
    "\n",
    "def to_api_url(url: str):\n",
    "    return url[:url.rindex(\"#\")]\\\n",
    "        .replace(\"github.com/\", \"api.github.com/repos/\")\\\n",
    "        .replace(\"/pull/\", \"/pulls/\")\n",
    "\n",
    "def get_prs():\n",
    "    seen = set()\n",
    "    for l in data.load():\n",
    "        if l[\"URL\"] is not None:\n",
    "            url = to_api_url(l[\"URL\"])\n",
    "            if url not in seen:\n",
    "                seen.add(url)\n",
    "                yield url\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "10000 PR Objects\n",
      "5000 Were Merged\n",
      "63650 review comments\n",
      "42694 issue comments\n",
      "106344 total comments\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Uncomment to re-load data (and comment out the load-from-file line)\n",
    "\n",
    "# pr_docs = []\n",
    "# \n",
    "# TOTAL_DOCS = 10_000\n",
    "# \n",
    "# # progress bar will be inaccurate as we don't know how many will be merged.  Set to 110% of needed as an estimate\n",
    "# pbar = tqdm(total=int(TOTAL_DOCS * 1.1), desc=\"Loading PRs\", unit=\"pr\")\n",
    "# skipped = 0\n",
    "# \n",
    "# total_merged = 0\n",
    "# total_unmerged = 0\n",
    "# \n",
    "# for pr_url in get_prs():\n",
    "#     try:\n",
    "#         repo, num = data.PR.repo_and_num_from_api_url(pr_url)\n",
    "#         doc = data.PR.create_from_api(repo, num)\n",
    "# \n",
    "#         text = \"  \".join(doc.all_comments).replace(\"\\\\n\", \"  \")\n",
    "# \n",
    "#         if detect(text) != 'en':\n",
    "#             skipped  += 1\n",
    "#             continue\n",
    "# \n",
    "#         if total_merged >= int(TOTAL_DOCS / 2) and doc.merged:\n",
    "#             continue\n",
    "# \n",
    "#         if total_unmerged >= int(TOTAL_DOCS / 2) and not doc.merged:\n",
    "#             continue\n",
    "# \n",
    "#         pr_docs.append(doc)\n",
    "#         pbar.update()\n",
    "# \n",
    "#         if doc.merged:\n",
    "#             total_merged += 1\n",
    "#         else:\n",
    "#             total_unmerged += 1\n",
    "# \n",
    "#     except Exception as e:\n",
    "#         skipped  += 1\n",
    "# \n",
    "#     pbar.set_postfix_str(\"Skipped: \" + str(skipped) + \" - Merged: \" + str(total_merged))\n",
    "# \n",
    "#     if len(pr_docs) == TOTAL_DOCS:\n",
    "#         break\n",
    "# \n",
    "# pickle.dump(pr_docs, gzip.open(data.prs_obj_file, 'wb+', 9))\n",
    "\n",
    "pr_docs: List[data.PR] = pickle.load(gzip.open(data.prs_obj_file, 'rb', 9))\n",
    "\n",
    "print(len(pr_docs), \"PR Objects\")\n",
    "print(sum(1 if p.merged else 0 for p in pr_docs), \"Were Merged\")\n",
    "\n",
    "print(sum(len(p.review_comments) for p in pr_docs), \"review comments\")\n",
    "print(sum(len(p.issue_comments) for p in pr_docs), \"issue comments\")\n",
    "print(sum(len(p.all_comments) for p in pr_docs), \"total comments\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Example: gtk-rs/glib - 231\n",
      "Comments:\n",
      " @GuillaumeGomez @EPashkin Any comments on this? Once this and the gir change landed, we need to regenerate all bindings that come with signals.\n",
      "-------------------------------------\n",
      "Ah sorry, I said it on IRC but I repeat here as well: I like it. All good for me!\n",
      "-------------------------------------\n",
      "`handler as u64`?\n",
      "-------------------------------------\n",
      "I meant: you lost conversion.\n",
      "-------------------------------------\n",
      "No, it's internally all based on c_ulong now again, like the FFI functions. No cast is needed here unless you meant something else.\n",
      "-------------------------------------\n",
      "Seems this not fully so:\r\n",
      "```\r\n",
      "error[E0277]: the trait bound `signal::SignalHandlerId: translate::FromGlib<u64>` is not satisfied\r\n",
      "  --> src\\signal.rs:57:5\r\n",
      "   |\r\n",
      "57 |     from_glib(handle)\r\n",
      "   |     ^^^^^^^^^ the trait `translate::FromGlib<u64>` is not implemented for `signal::SignalHandlerId`\r\n",
      "   |\r\n",
      "   = help: the following implementations were found:\r\n",
      "             <signal::SignalHandlerId as translate::FromGlib<u32>>\r\n",
      "   = note: required by `translate::from_glib`\r\n",
      "```\n",
      "-------------------------------------\n",
      "There was a cast right in the line above, which would have to be removed. Done! Thanks for noticing\n",
      "-------------------------------------\n",
      "FWIW, this would've only failed on Windows (32/64 bit) and 32 bit variants of other platforms. Elsewhere c_ulong and u64 are equivalent.\n",
      "-------------------------------------\n",
      "üëç for merge.\n",
      "-------------------------------------\n",
      "Or it need regen with https://github.com/gtk-rs/gir/pull/454?\n",
      "-------------------------------------\n",
      "It needs regen with https://github.com/gtk-rs/gir/pull/453\n",
      "-------------------------------------\n",
      "Let's wait for the regen then! :)\n",
      "-------------------------------------\n",
      "The regens won't compile without having this GLib change merged first.\n",
      "-------------------------------------\n",
      "@GuillaumeGomez Or do you want all regens first, not compiling, and then merge it all in one go?\n",
      "-------------------------------------\n",
      "It's always so annoying... Let's merge this one first!\n",
      "-------------------------------------\n",
      "It definitely is, yes. Once you get https://github.com/gtk-rs/gir/pull/454 and https://github.com/gtk-rs/glib/pull/232 in, I'll send regens for everything. Otherwise there would have to be regens twice\n",
      "\n",
      "\n",
      "\n",
      "Issue Comments:\n",
      " @GuillaumeGomez @EPashkin Any comments on this? Once this and the gir change landed, we need to regenerate all bindings that come with signals.\n",
      "-------------------------------------\n",
      "Ah sorry, I said it on IRC but I repeat here as well: I like it. All good for me!\n",
      "-------------------------------------\n",
      "üëç for merge.\n",
      "-------------------------------------\n",
      "Or it need regen with https://github.com/gtk-rs/gir/pull/454?\n",
      "-------------------------------------\n",
      "It needs regen with https://github.com/gtk-rs/gir/pull/453\n",
      "-------------------------------------\n",
      "Let's wait for the regen then! :)\n",
      "-------------------------------------\n",
      "The regens won't compile without having this GLib change merged first.\n",
      "-------------------------------------\n",
      "@GuillaumeGomez Or do you want all regens first, not compiling, and then merge it all in one go?\n",
      "-------------------------------------\n",
      "It's always so annoying... Let's merge this one first!\n",
      "-------------------------------------\n",
      "It definitely is, yes. Once you get https://github.com/gtk-rs/gir/pull/454 and https://github.com/gtk-rs/glib/pull/232 in, I'll send regens for everything. Otherwise there would have to be regens twice\n",
      "\n",
      "\n",
      "\n",
      "Code Review Comments:\n",
      " `handler as u64`?\n",
      "-------------------------------------\n",
      "I meant: you lost conversion.\n",
      "-------------------------------------\n",
      "No, it's internally all based on c_ulong now again, like the FFI functions. No cast is needed here unless you meant something else.\n",
      "-------------------------------------\n",
      "Seems this not fully so:\r\n",
      "```\r\n",
      "error[E0277]: the trait bound `signal::SignalHandlerId: translate::FromGlib<u64>` is not satisfied\r\n",
      "  --> src\\signal.rs:57:5\r\n",
      "   |\r\n",
      "57 |     from_glib(handle)\r\n",
      "   |     ^^^^^^^^^ the trait `translate::FromGlib<u64>` is not implemented for `signal::SignalHandlerId`\r\n",
      "   |\r\n",
      "   = help: the following implementations were found:\r\n",
      "             <signal::SignalHandlerId as translate::FromGlib<u32>>\r\n",
      "   = note: required by `translate::from_glib`\r\n",
      "```\n",
      "-------------------------------------\n",
      "There was a cast right in the line above, which would have to be removed. Done! Thanks for noticing\n",
      "-------------------------------------\n",
      "FWIW, this would've only failed on Windows (32/64 bit) and 32 bit variants of other platforms. Elsewhere c_ulong and u64 are equivalent.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "doc = pr_docs[3]\n",
    "print(\"Example:\", doc.repo, \"-\", doc.pr_number)\n",
    "print(\"Comments:\\n\", \"\\n-------------------------------------\\n\".join(doc.all_comments))\n",
    "print(\"\\n\\n\\nIssue Comments:\\n\", \"\\n-------------------------------------\\n\".join(doc.issue_comments))\n",
    "print(\"\\n\\n\\nCode Review Comments:\\n\", \"\\n-------------------------------------\\n\".join(doc.review_comments))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Example: tibbe/unordered-containers - 132\n",
      "Comments:\n",
      " Nitpick: end sentences in a dot.\n",
      "\n",
      "-------------------------------------\n",
      "oops, thanks, fixed\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Issue Comments:\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "Code Review Comments:\n",
      " Nitpick: end sentences in a dot.\n",
      "\n",
      "-------------------------------------\n",
      "oops, thanks, fixed\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "doc = pr_docs[5]\n",
    "print(\"Example:\", doc.repo, \"-\", doc.pr_number)\n",
    "print(\"Comments:\\n\", \"\\n-------------------------------------\\n\".join(doc.all_comments))\n",
    "print(\"\\n\\n\\nIssue Comments:\\n\", \"\\n-------------------------------------\\n\".join(doc.issue_comments))\n",
    "print(\"\\n\\n\\nCode Review Comments:\\n\", \"\\n-------------------------------------\\n\".join(doc.review_comments))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [5:00:48<00:00,  1.33s/it]  \n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# all_data = []\n",
    "# errored = 0\n",
    "# \n",
    "# for pr in tqdm(pr_docs):\n",
    "#     try:\n",
    "#         pr: data.PR\n",
    "#         pr_data = data.github_api(pr.api_url)\n",
    "#     \n",
    "#         issue_comments = data.github_api(pr.issue_comments_api_url)\n",
    "# \n",
    "#         review_comments = data.github_api(pr.review_comments_api_url)\n",
    "#             \n",
    "#         all_data.append({\n",
    "#             \"pr\": pr,\n",
    "#             \"pr_data\": pr_data,\n",
    "#             \"issue_comments\": issue_comments,\n",
    "#             \"review_comments\": review_comments\n",
    "#         })\n",
    "#     except Exception:\n",
    "#         errored += 1\n",
    "# "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9977/9977 [00:03<00:00, 3269.44it/s]\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "Comments Made After Close: 3263\n",
      "PRs with comments after close: 1375\n",
      "Errored: 23\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# made_after_close = 0\n",
    "# amount_after_close = 0\n",
    "# for data in tqdm(all_data):\n",
    "#     try:\n",
    "#         pr = data[\"pr\"]\n",
    "#         pr_data = data[\"pr_data\"]\n",
    "#         issue_comments = data[\"issue_comments\"]\n",
    "#         review_comments = data[\"review_comments\"]\n",
    "#         \n",
    "#         ended_at = datetime.strptime(pr_data['closed_at'], \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "#         ended_at += timedelta(minutes=5)\n",
    "#         \n",
    "#         issue_dates = [datetime.strptime(x['created_at'], \"%Y-%m-%dT%H:%M:%SZ\") for x in issue_comments]\n",
    "# \n",
    "#         was_after = False\n",
    "# \n",
    "#         for d in issue_dates:\n",
    "#             if d > ended_at:\n",
    "#                 amount_after_close +=  1\n",
    "#                 was_after = True\n",
    "# \n",
    "#         review_dates = [datetime.strptime(x['created_at'], \"%Y-%m-%dT%H:%M:%SZ\") for x in review_comments]\n",
    "# \n",
    "#         for d in review_dates:\n",
    "#             if d > ended_at:\n",
    "#                 amount_after_close +=  1\n",
    "#                 was_after = True\n",
    "#         \n",
    "#         if was_after:\n",
    "#             made_after_close += 1\n",
    "#             # print(pr.api_url)\n",
    "#             # print(pr.issue_comments_api_url)\n",
    "#             # print(pr.review_comments_api_url)\n",
    "#             # break\n",
    "#         \n",
    "#         # print(pr_data)\n",
    "#     except Exception as e:\n",
    "#         errored += 1\n",
    "#         \n",
    "# print(\"Comments Made After Close:\", amount_after_close)  # 4214\n",
    "# print(\"PRs with comments after close:\", made_after_close)  # 1915\n",
    "# print(\"Errored:\", errored)\n",
    "# "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9977/9977 [00:00<00:00, 232033.64it/s]\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "0\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# states = set()\n",
    "# \n",
    "# open = 0\n",
    "# for data in tqdm(all_data):\n",
    "#     states.add(data[\"pr_data\"][\"state\"])\n",
    "#     if data[\"pr_data\"][\"state\"] != \"closed\":\n",
    "#         open += 1\n",
    "#         \n",
    "# print(open)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}